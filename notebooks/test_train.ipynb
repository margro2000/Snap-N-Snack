{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from datasets.img_dataset import FoodImgs\n",
    "from models.cnn import SnapSnack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6363 train imgs \n",
      "1363 val imgs\n",
      "1364 test imgs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import math\n",
    "from torchvision import transforms as T\n",
    "\n",
    "transforms = T.Compose(\n",
    "                [\n",
    "                    T.Resize(256),\n",
    "                    T.CenterCrop(224),\n",
    "                    T.ToTensor(),\n",
    "                    T.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "dataset = FoodImgs(\n",
    "    transforms = transforms,\n",
    ")\n",
    "\n",
    "s = len(dataset)\n",
    "train_size = int(math.ceil(s * 0.7))\n",
    "test_size = int(math.ceil(s * 0.15))\n",
    "val_size = s - test_size - train_size\n",
    "\n",
    "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "print(f\"{len(train_set)} train imgs \\n{len(val_set)} val imgs\\n{len(test_set)} test imgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:308pir1x) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29032<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/Users/davinan/Dropbox/github/Snap-N-Snack/notebooks/wandb/run-20201205_191008-308pir1x/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/Users/davinan/Dropbox/github/Snap-N-Snack/notebooks/wandb/run-20201205_191008-308pir1x/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>avg_val_loss</td><td>0.26492</td></tr><tr><td>_step</td><td>126</td></tr><tr><td>_runtime</td><td>141</td></tr><tr><td>_timestamp</td><td>1607213552</td></tr><tr><td>loss</td><td>3.01415</td></tr><tr><td>batch_nb</td><td>125</td></tr><tr><td>r2_calories</td><td>0.0</td></tr><tr><td>r2_proteins</td><td>0.0</td></tr><tr><td>r2_fat</td><td>0.0</td></tr><tr><td>r2_sodium</td><td>0.0</td></tr><tr><td>r2_overall</td><td>0.0</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>avg_val_loss</td><td>▁</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>loss</td><td>▁▇▂█▅▄▃▂▃▄▆▅▇▇▅▂▅▄▅▃▃▂▃▄▇▆▅█▇█▆▇▅▅▅▆▆▄▅▂</td></tr><tr><td>batch_nb</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>r2_calories</td><td>██████████████████████████████▁█████████</td></tr><tr><td>r2_proteins</td><td>▁███████████████████████████████████████</td></tr><tr><td>r2_fat</td><td>▁███████████████████████████████████████</td></tr><tr><td>r2_sodium</td><td>██████████████████ ▁████████████████████</td></tr><tr><td>r2_overall</td><td>██████████████████ ███████████▁█████████</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">crimson-monkey-91</strong>: <a href=\"https://wandb.ai/davinan/snapnsnack/runs/308pir1x\" target=\"_blank\">https://wandb.ai/davinan/snapnsnack/runs/308pir1x</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:308pir1x). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.12 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.10<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">proud-wind-92</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/davinan/snapnsnack\" target=\"_blank\">https://wandb.ai/davinan/snapnsnack</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/davinan/snapnsnack/runs/14i98zew\" target=\"_blank\">https://wandb.ai/davinan/snapnsnack/runs/14i98zew</a><br/>\n",
       "                Run data is saved locally in <code>/Users/davinan/Dropbox/github/Snap-N-Snack/notebooks/wandb/run-20201205_192853-14i98zew</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type      | Params\n",
      "---------------------------------------\n",
      "0 | backbone | ResNet    | 11 M  \n",
      "1 | softmax  | Softmax   | 0     \n",
      "2 | loss     | KLDivLoss | 0     \n",
      "/opt/anaconda3/envs/py36/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([176.,   5.,   7.,  41.])\n",
      "tensor([1552.,   60.,  106., 3916.])\n",
      "tensor([153.,   5.,  10.,  53.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py36/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The validation_epoch_end should not return anything as of 9.1.to log, use self.log(...) or self.write(...) directly in the LightningModule\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/opt/anaconda3/envs/py36/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9784d13973434f2992594bb0cade62f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 51.,   1.,   3., 107.])\n",
      "tensor([88.,  0.,  9.,  0.])\n",
      "tensor([282.,   4.,  14.,  15.])\n",
      "tensor([202.,   7.,  10.,  52.])\n",
      "tensor([270.,   4.,   0.,  57.])\n",
      "tensor([713.,  60.,  51., 971.])\n",
      "tensor([[0.1100, 0.1425, 0.4116, 0.3360],\n",
      "        [0.1366, 0.1927, 0.3242, 0.3464],\n",
      "        [0.1427, 0.1867, 0.3309, 0.3397]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.3148, 0.0062, 0.0185, 0.6605],\n",
      "        [0.9072, 0.0000, 0.0928, 0.0000],\n",
      "        [0.8952, 0.0127, 0.0444, 0.0476]])\n",
      "1.2430739402770996\n",
      "================\n",
      "tensor([167.,   3.,   7.,  97.])\n",
      "tensor([194.,   2.,   3., 697.])\n",
      "tensor([906.,  57.,  53., 284.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7454, 0.0258, 0.0369, 0.1919],\n",
      "        [0.8157, 0.0121, 0.0000, 0.1722],\n",
      "        [0.3972, 0.0334, 0.0284, 0.5409]])\n",
      "4.8672332763671875\n",
      "================\n",
      "tensor([940., 100.,  38., 800.])\n",
      "tensor([168.,  14.,  10., 460.])\n",
      "tensor([336.,  44.,  16., 413.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6095, 0.0109, 0.0255, 0.3540],\n",
      "        [0.2165, 0.0022, 0.0033, 0.7779],\n",
      "        [0.6969, 0.0438, 0.0408, 0.2185]])\n",
      "7.194716930389404\n",
      "================\n",
      "tensor([586.,  16.,  22., 954.])\n",
      "tensor([414.,  20.,  29., 998.])\n",
      "tensor([318.,  20.,  17., 185.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5005, 0.0532, 0.0202, 0.4260],\n",
      "        [0.2577, 0.0215, 0.0153, 0.7055],\n",
      "        [0.4153, 0.0544, 0.0198, 0.5105]])\n",
      "8.936010360717773\n",
      "================\n",
      "tensor([374.,  16.,  19., 590.])\n",
      "tensor([724.,   8.,  34., 552.])\n",
      "tensor([149.,   3.,   5., 634.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.3714, 0.0101, 0.0139, 0.6046],\n",
      "        [0.2834, 0.0137, 0.0198, 0.6831],\n",
      "        [0.5889, 0.0370, 0.0315, 0.3426]])\n",
      "8.622469902038574\n",
      "================\n",
      "tensor([421.,  10.,  33., 383.])\n",
      "tensor([438.,  32.,  23., 158.])\n",
      "tensor([100.,   0.,   0.,   3.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.3744, 0.0160, 0.0190, 0.5906],\n",
      "        [0.5493, 0.0061, 0.0258, 0.4188],\n",
      "        [0.1884, 0.0038, 0.0063, 0.8015]])\n",
      "9.415233612060547\n",
      "================\n",
      "tensor([414.,  20.,  29., 998.])\n",
      "tensor([1.8000e+02, 4.0000e+00, 2.0000e+00, 4.5166e+04])\n",
      "tensor([749.,   1.,  73., 937.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4970, 0.0118, 0.0390, 0.4522],\n",
      "        [0.6728, 0.0492, 0.0353, 0.2427],\n",
      "        [0.9709, 0.0000, 0.0000, 0.0291]])\n",
      "3.9854576587677\n",
      "================\n",
      "tensor([ 518.,   23.,   26., 1079.])\n",
      "tensor([325.,  10.,  24., 300.])\n",
      "tensor([250.,  33.,  11., 123.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2.8337e-01, 1.3689e-02, 1.9849e-02, 6.8309e-01],\n",
      "        [3.9690e-03, 8.8199e-05, 4.4099e-05, 9.9590e-01],\n",
      "        [4.2557e-01, 5.6818e-04, 4.1477e-02, 5.3239e-01]])\n",
      "11.748888969421387\n",
      "================\n",
      "tensor([256.,   4.,   5.,  30.])\n",
      "tensor([105.,   6.,   9., 281.])\n",
      "tensor([ 932.,   70.,   64., 4626.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.3147, 0.0140, 0.0158, 0.6555],\n",
      "        [0.4932, 0.0152, 0.0364, 0.4552],\n",
      "        [0.5995, 0.0791, 0.0264, 0.2950]])\n",
      "7.683119297027588\n",
      "================\n",
      "tensor([354.,  16.,  20., 575.])\n",
      "tensor([4471.,   41.,  204., 5265.])\n",
      "tensor([570.,  57.,  31., 188.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8678, 0.0136, 0.0169, 0.1017],\n",
      "        [0.2618, 0.0150, 0.0224, 0.7007],\n",
      "        [0.1637, 0.0123, 0.0112, 0.8127]])\n",
      "8.569001197814941\n",
      "================\n",
      "tensor([333.,  11.,  18., 131.])\n",
      "tensor([740.,  13.,  33., 488.])\n",
      "tensor([169.,   4.,   9., 990.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.3668, 0.0166, 0.0207, 0.5959],\n",
      "        [0.4480, 0.0041, 0.0204, 0.5275],\n",
      "        [0.6738, 0.0674, 0.0366, 0.2222]])\n",
      "7.2781982421875\n",
      "================\n",
      "tensor([19.,  1.,  1., 31.])\n",
      "tensor([272.,  10.,   3.,  15.])\n",
      "tensor([  86.,    6.,    6., 2402.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6755, 0.0223, 0.0365, 0.2657],\n",
      "        [0.5808, 0.0102, 0.0259, 0.3830],\n",
      "        [0.1442, 0.0034, 0.0077, 0.8447]])\n",
      "7.884946823120117\n",
      "================\n",
      "tensor([376.,  22.,  29., 106.])\n",
      "tensor([1724.,   73.,  127., 1824.])\n",
      "tensor([237.,   9.,  21., 226.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.3654, 0.0192, 0.0192, 0.5962],\n",
      "        [0.9067, 0.0333, 0.0100, 0.0500],\n",
      "        [0.0344, 0.0024, 0.0024, 0.9608]])\n",
      "8.629077911376953\n",
      "================\n",
      "tensor([245.,  17.,  15., 405.])\n",
      "tensor([230.,   2.,   7.,   9.])\n",
      "tensor([232.,   4.,   9.,  17.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7054, 0.0413, 0.0544, 0.1989],\n",
      "        [0.4600, 0.0195, 0.0339, 0.4867],\n",
      "        [0.4807, 0.0183, 0.0426, 0.4584]])\n",
      "6.382632732391357\n",
      "================\n",
      "tensor([202.,   1.,   2., 200.])\n",
      "tensor([ 819.,   46.,   49., 1331.])\n",
      "tensor([654.,   7.,  36., 251.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.3592, 0.0249, 0.0220, 0.5938],\n",
      "        [0.9274, 0.0081, 0.0282, 0.0363],\n",
      "        [0.8855, 0.0153, 0.0344, 0.0649]])\n",
      "3.898495674133301\n",
      "================\n",
      "tensor([275.,   6.,  13., 242.])\n",
      "tensor([585.,  23.,  39., 854.])\n",
      "tensor([176.,   2.,   6.,  17.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4988, 0.0025, 0.0049, 0.4938],\n",
      "        [0.3648, 0.0205, 0.0218, 0.5929],\n",
      "        [0.6899, 0.0074, 0.0380, 0.2648]])\n",
      "6.989948272705078\n",
      "================\n",
      "tensor([230.,   2.,   1.,   8.])\n",
      "tensor([ 599.,   48.,   28., 1038.])\n",
      "tensor([311.,   4.,  20.,  19.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5131, 0.0112, 0.0243, 0.4515],\n",
      "        [0.3897, 0.0153, 0.0260, 0.5690],\n",
      "        [0.8756, 0.0100, 0.0299, 0.0846]])\n",
      "5.841571807861328\n",
      "================\n",
      "tensor([485.,   7.,  23., 339.])\n",
      "tensor([1919.,   29.,  123.,  610.])\n",
      "tensor([273.,   4.,  12., 273.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.9544, 0.0083, 0.0041, 0.0332],\n",
      "        [0.3497, 0.0280, 0.0163, 0.6060],\n",
      "        [0.8785, 0.0113, 0.0565, 0.0537]])\n",
      "3.877722978591919\n",
      "================\n",
      "tensor([187.,   1.,   0., 787.])\n",
      "tensor([954.,  14.,  66., 767.])\n",
      "tensor([ 296.,    8.,   23., 1564.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5679, 0.0082, 0.0269, 0.3970],\n",
      "        [0.7158, 0.0108, 0.0459, 0.2275],\n",
      "        [0.4858, 0.0071, 0.0214, 0.4858]])\n",
      "5.807945251464844\n",
      "================\n",
      "tensor([249.,   8.,  20., 242.])\n",
      "tensor([767.,  65.,  45., 647.])\n",
      "tensor([200.,   2.,  17., 150.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1918, 0.0010, 0.0000, 0.8072],\n",
      "        [0.5297, 0.0078, 0.0366, 0.4259],\n",
      "        [0.1565, 0.0042, 0.0122, 0.8271]])\n",
      "10.774097442626953\n",
      "================\n",
      "tensor([ 364.,   16.,   10., 2094.])\n",
      "tensor([456.,   4.,  30., 148.])\n",
      "tensor([1010.,   54.,   72.,  689.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4798, 0.0154, 0.0385, 0.4663],\n",
      "        [0.5033, 0.0427, 0.0295, 0.4245],\n",
      "        [0.5420, 0.0054, 0.0461, 0.4065]])\n",
      "7.019864559173584\n",
      "================\n",
      "tensor([374.,  16.,  19., 590.])\n",
      "tensor([169.,   4.,   9., 990.])\n",
      "tensor([308.,   6.,  16.,  53.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1465, 0.0064, 0.0040, 0.8430],\n",
      "        [0.7147, 0.0063, 0.0470, 0.2320],\n",
      "        [0.5534, 0.0296, 0.0395, 0.3775]])\n",
      "7.796855926513672\n",
      "================\n",
      "tensor([180.,   4.,   9., 279.])\n",
      "tensor([394.,   2.,  41.,  58.])\n",
      "tensor([ 476.,   47.,   29., 1026.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.3744, 0.0160, 0.0190, 0.5906],\n",
      "        [0.1442, 0.0034, 0.0077, 0.8447],\n",
      "        [0.8042, 0.0157, 0.0418, 0.1384]])\n",
      "8.362789154052734\n",
      "================\n",
      "tensor([27.,  1.,  1., 50.])\n",
      "tensor([221.,   6.,  17.,  52.])\n",
      "tensor([ 45.,   2.,   1., 166.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.3814, 0.0085, 0.0191, 0.5911],\n",
      "        [0.7960, 0.0040, 0.0828, 0.1172],\n",
      "        [0.3016, 0.0298, 0.0184, 0.6502]])\n",
      "7.413624286651611\n",
      "================\n",
      "tensor([268.,   6.,   1.,  50.])\n",
      "tensor([ 50.,   3.,   4., 113.])\n",
      "tensor([335.,  13.,  29., 111.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.3418, 0.0127, 0.0127, 0.6329],\n",
      "        [0.7466, 0.0203, 0.0574, 0.1757],\n",
      "        [0.2103, 0.0093, 0.0047, 0.7757]])\n",
      "8.431538581848145\n",
      "================\n",
      "tensor([126.,  15.,   3., 907.])\n",
      "tensor([329.,   4.,  20.,  31.])\n",
      "tensor([410.,   5.,  44., 360.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.8246, 0.0185, 0.0031, 0.1538],\n",
      "        [0.2941, 0.0176, 0.0235, 0.6647],\n",
      "        [0.6865, 0.0266, 0.0594, 0.2275]])\n",
      "5.689669132232666\n",
      "================\n",
      "tensor([ 752.,   32.,   31., 1065.])\n",
      "tensor([187.,   1.,   0., 787.])\n",
      "tensor([ 47.,   2.,   1., 473.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1199, 0.0143, 0.0029, 0.8630],\n",
      "        [0.8568, 0.0104, 0.0521, 0.0807],\n",
      "        [0.5006, 0.0061, 0.0537, 0.4396]])\n",
      "7.5505828857421875\n",
      "================\n",
      "tensor([133.,   2.,   8.,  91.])\n",
      "tensor([275.,  14.,  16., 120.])\n",
      "tensor([97.,  2.,  4., 81.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4000, 0.0170, 0.0165, 0.5665],\n",
      "        [0.1918, 0.0010, 0.0000, 0.8072],\n",
      "        [0.0899, 0.0038, 0.0019, 0.9044]])\n",
      "11.901463508605957\n",
      "================\n",
      "tensor([ 277.,   10.,    6., 1274.])\n",
      "tensor([241.,   7.,  19., 280.])\n",
      "tensor([313.,   7.,  14.,  45.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5684, 0.0085, 0.0342, 0.3889],\n",
      "        [0.6471, 0.0329, 0.0376, 0.2824],\n",
      "        [0.5272, 0.0109, 0.0217, 0.4402]])\n",
      "5.90550422668457\n",
      "================\n",
      "tensor([629.,  28.,  52., 292.])\n",
      "tensor([367.,  11.,  16., 506.])\n",
      "tensor([100.,   2.,   9., 153.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1768, 0.0064, 0.0038, 0.8130],\n",
      "        [0.4406, 0.0128, 0.0347, 0.5119],\n",
      "        [0.8259, 0.0185, 0.0369, 0.1187]])\n",
      "7.693754196166992\n",
      "================\n",
      "tensor([233.,  17.,  15., 154.])\n",
      "tensor([430.,   9.,  19., 364.])\n",
      "tensor([724.,   8.,  34., 552.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6284, 0.0280, 0.0519, 0.2917],\n",
      "        [0.4078, 0.0122, 0.0178, 0.5622],\n",
      "        [0.3788, 0.0076, 0.0341, 0.5795]])\n",
      "7.664034366607666\n",
      "================\n",
      "tensor([1068.,   50.,   93.,  560.])\n",
      "tensor([336.,  44.,  16., 413.])\n",
      "tensor([151.,   9.,   9., 652.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5561, 0.0406, 0.0358, 0.3675],\n",
      "        [0.5231, 0.0109, 0.0231, 0.4428],\n",
      "        [0.5493, 0.0061, 0.0258, 0.4188]])\n",
      "6.502382278442383\n",
      "================\n",
      "tensor([162.,   2.,   1., 153.])\n",
      "tensor([1143.,   63.,   77.,  311.])\n",
      "tensor([1054.,   56.,   73., 1690.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.6030, 0.0282, 0.0525, 0.3162],\n",
      "        [0.4153, 0.0544, 0.0198, 0.5105],\n",
      "        [0.1839, 0.0110, 0.0110, 0.7942]])\n",
      "8.837821006774902\n",
      "================\n",
      "tensor([304.,  19.,  25., 242.])\n",
      "tensor([412.,  30.,  12., 976.])\n",
      "tensor([92.,  1.,  6., 51.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5094, 0.0063, 0.0031, 0.4811],\n",
      "        [0.7171, 0.0395, 0.0483, 0.1951],\n",
      "        [0.3669, 0.0195, 0.0254, 0.5882]])\n",
      "6.748414993286133\n",
      "================\n",
      "tensor([158.,   4.,  10., 171.])\n",
      "tensor([495.,  30.,  38., 421.])\n",
      "tensor([9.3000e+01, 4.0000e+00, 5.0000e+00, 1.1298e+04])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5153, 0.0322, 0.0424, 0.4102],\n",
      "        [0.2881, 0.0210, 0.0084, 0.6825],\n",
      "        [0.6133, 0.0067, 0.0400, 0.3400]])\n",
      "7.666268825531006\n",
      "================\n",
      "tensor([1802.,   65.,   78.,  490.])\n",
      "tensor([367.,  11.,  16., 506.])\n",
      "tensor([ 37.,   1.,   0., 295.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[4.6064e-01, 1.1662e-02, 2.9155e-02, 4.9854e-01],\n",
      "        [5.0305e-01, 3.0488e-02, 3.8618e-02, 4.2785e-01],\n",
      "        [8.1579e-03, 3.5088e-04, 4.3860e-04, 9.9105e-01]])\n",
      "10.278542518615723\n",
      "================\n",
      "tensor([ 415.,   72.,   11., 8112.])\n",
      "tensor([1104.,   49.,   64., 2179.])\n",
      "tensor([282.,   4.,  14.,  15.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.7400, 0.0267, 0.0320, 0.2012],\n",
      "        [0.4078, 0.0122, 0.0178, 0.5622],\n",
      "        [0.1111, 0.0030, 0.0000, 0.8859]])\n",
      "8.708807945251465\n",
      "================\n",
      "tensor([126.,   2.,  11., 208.])\n",
      "tensor([241.,   7.,  19., 280.])\n",
      "tensor([158.,   2.,  12., 523.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.0482, 0.0084, 0.0013, 0.9422],\n",
      "        [0.3251, 0.0144, 0.0188, 0.6416],\n",
      "        [0.8952, 0.0127, 0.0444, 0.0476]])\n",
      "8.811123847961426\n",
      "================\n",
      "tensor([276.,   2.,   9.,  12.])\n",
      "tensor([199.,   6.,  12., 186.])\n",
      "tensor([523.,   8.,  19., 694.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py36/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "# wandb.init(project=\"snapnsnack\")\n",
    "wandb_logger = WandbLogger(project='snapnsnack')\n",
    "model = SnapSnack(fc_layers=(), output_dim=4, lr=1)\n",
    "trainer = pl.Trainer(logger=wandb_logger, max_epochs=5)\n",
    "trainer.fit(model, train_dataloader=DataLoader(train_set, batch_size=3), val_dataloaders=DataLoader(val_set), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>#cakeweek</th>\n",
       "      <th>#wasteless</th>\n",
       "      <th>22-minute meals</th>\n",
       "      <th>3-ingredient recipes</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow squash</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yonkers</th>\n",
       "      <th>yuca</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>cookbooks</th>\n",
       "      <th>leftovers</th>\n",
       "      <th>snack</th>\n",
       "      <th>snack week</th>\n",
       "      <th>turkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lentil, Apple, and Turkey Wrap</td>\n",
       "      <td>2.500</td>\n",
       "      <td>426.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boudin Blanc Terrine with Red Onion Confit</td>\n",
       "      <td>4.375</td>\n",
       "      <td>403.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Potato and Fennel Soup Hodge</td>\n",
       "      <td>3.750</td>\n",
       "      <td>165.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mahi-Mahi in Tomato Olive Sauce</td>\n",
       "      <td>5.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spinach Noodle Casserole</td>\n",
       "      <td>3.125</td>\n",
       "      <td>547.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  rating  calories  protein  \\\n",
       "0              Lentil, Apple, and Turkey Wrap    2.500     426.0     30.0   \n",
       "1  Boudin Blanc Terrine with Red Onion Confit    4.375     403.0     18.0   \n",
       "2                Potato and Fennel Soup Hodge    3.750     165.0      6.0   \n",
       "3             Mahi-Mahi in Tomato Olive Sauce    5.000       NaN      NaN   \n",
       "4                    Spinach Noodle Casserole    3.125     547.0     20.0   \n",
       "\n",
       "    fat  sodium  #cakeweek  #wasteless  22-minute meals  3-ingredient recipes  \\\n",
       "0   7.0   559.0        0.0         0.0              0.0                   0.0   \n",
       "1  23.0  1439.0        0.0         0.0              0.0                   0.0   \n",
       "2   7.0   165.0        0.0         0.0              0.0                   0.0   \n",
       "3   NaN     NaN        0.0         0.0              0.0                   0.0   \n",
       "4  32.0   452.0        0.0         0.0              0.0                   0.0   \n",
       "\n",
       "   ...  yellow squash  yogurt  yonkers  yuca  zucchini  cookbooks  leftovers  \\\n",
       "0  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "1  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "2  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "3  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "4  ...            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "\n",
       "   snack  snack week  turkey  \n",
       "0    0.0         0.0     1.0  \n",
       "1    0.0         0.0     0.0  \n",
       "2    0.0         0.0     0.0  \n",
       "3    0.0         0.0     0.0  \n",
       "4    0.0         0.0     0.0  \n",
       "\n",
       "[5 rows x 680 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "epi = pd.read_csv(\"../data/snapnsnackdb/epi_r.csv\")\n",
    "\n",
    "epi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_4 = \"/Users/davinan/Dropbox/github/Snap-N-Snack/data/snapnsnackdb/simple_images/Spinach+Noodle+Casserole+/Spinach+Noodle+Casserole+_1.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "im = plt.imread(img_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "transform = T.Compose(\n",
    "            [\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "                T.Resize(256),\n",
    "                T.CenterCrop(224),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "model.eval()\n",
    "oi = transform(Image.fromarray(im)).unsqueeze(0)\n",
    "preds = model(oi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  3.7612, 327.7388,  11.6335,  22.7230, 274.9613]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>#cakeweek</th>\n",
       "      <th>#wasteless</th>\n",
       "      <th>22-minute meals</th>\n",
       "      <th>3-ingredient recipes</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow squash</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yonkers</th>\n",
       "      <th>yuca</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>cookbooks</th>\n",
       "      <th>leftovers</th>\n",
       "      <th>snack</th>\n",
       "      <th>snack week</th>\n",
       "      <th>turkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lentil, Apple, and Turkey Wrap</td>\n",
       "      <td>2.500</td>\n",
       "      <td>426.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boudin Blanc Terrine with Red Onion Confit</td>\n",
       "      <td>4.375</td>\n",
       "      <td>403.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Potato and Fennel Soup Hodge</td>\n",
       "      <td>3.750</td>\n",
       "      <td>165.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spinach Noodle Casserole</td>\n",
       "      <td>3.125</td>\n",
       "      <td>547.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Best Blts</td>\n",
       "      <td>4.375</td>\n",
       "      <td>948.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1042.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20047</th>\n",
       "      <td>Parmesan Puffs</td>\n",
       "      <td>3.125</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20048</th>\n",
       "      <td>Artichoke and Parmesan Risotto</td>\n",
       "      <td>4.375</td>\n",
       "      <td>671.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20049</th>\n",
       "      <td>Turkey Cream Puff Pie</td>\n",
       "      <td>4.375</td>\n",
       "      <td>563.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20050</th>\n",
       "      <td>Snapper on Angel Hair with Citrus Cream</td>\n",
       "      <td>4.375</td>\n",
       "      <td>631.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20051</th>\n",
       "      <td>Baked Ham with Marmalade-Horseradish Glaze</td>\n",
       "      <td>4.375</td>\n",
       "      <td>560.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3698.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15864 rows × 680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  rating  calories  protein  \\\n",
       "0                  Lentil, Apple, and Turkey Wrap    2.500     426.0     30.0   \n",
       "1      Boudin Blanc Terrine with Red Onion Confit    4.375     403.0     18.0   \n",
       "2                    Potato and Fennel Soup Hodge    3.750     165.0      6.0   \n",
       "4                        Spinach Noodle Casserole    3.125     547.0     20.0   \n",
       "5                                   The Best Blts    4.375     948.0     19.0   \n",
       "...                                            ...     ...       ...      ...   \n",
       "20047                              Parmesan Puffs    3.125      28.0      2.0   \n",
       "20048              Artichoke and Parmesan Risotto    4.375     671.0     22.0   \n",
       "20049                       Turkey Cream Puff Pie    4.375     563.0     31.0   \n",
       "20050     Snapper on Angel Hair with Citrus Cream    4.375     631.0     45.0   \n",
       "20051  Baked Ham with Marmalade-Horseradish Glaze    4.375     560.0     73.0   \n",
       "\n",
       "        fat  sodium  #cakeweek  #wasteless  22-minute meals  \\\n",
       "0       7.0   559.0        0.0         0.0              0.0   \n",
       "1      23.0  1439.0        0.0         0.0              0.0   \n",
       "2       7.0   165.0        0.0         0.0              0.0   \n",
       "4      32.0   452.0        0.0         0.0              0.0   \n",
       "5      79.0  1042.0        0.0         0.0              0.0   \n",
       "...     ...     ...        ...         ...              ...   \n",
       "20047   2.0    64.0        0.0         0.0              0.0   \n",
       "20048  28.0   583.0        0.0         0.0              0.0   \n",
       "20049  38.0   652.0        0.0         0.0              0.0   \n",
       "20050  24.0   517.0        0.0         0.0              0.0   \n",
       "20051  10.0  3698.0        0.0         0.0              0.0   \n",
       "\n",
       "       3-ingredient recipes  ...  yellow squash  yogurt  yonkers  yuca  \\\n",
       "0                       0.0  ...            0.0     0.0      0.0   0.0   \n",
       "1                       0.0  ...            0.0     0.0      0.0   0.0   \n",
       "2                       0.0  ...            0.0     0.0      0.0   0.0   \n",
       "4                       0.0  ...            0.0     0.0      0.0   0.0   \n",
       "5                       0.0  ...            0.0     0.0      0.0   0.0   \n",
       "...                     ...  ...            ...     ...      ...   ...   \n",
       "20047                   0.0  ...            0.0     0.0      0.0   0.0   \n",
       "20048                   0.0  ...            0.0     0.0      0.0   0.0   \n",
       "20049                   0.0  ...            0.0     0.0      0.0   0.0   \n",
       "20050                   0.0  ...            0.0     0.0      0.0   0.0   \n",
       "20051                   0.0  ...            0.0     0.0      0.0   0.0   \n",
       "\n",
       "       zucchini  cookbooks  leftovers  snack  snack week  turkey  \n",
       "0           0.0        0.0        0.0    0.0         0.0     1.0  \n",
       "1           0.0        0.0        0.0    0.0         0.0     0.0  \n",
       "2           0.0        0.0        0.0    0.0         0.0     0.0  \n",
       "4           0.0        0.0        0.0    0.0         0.0     0.0  \n",
       "5           0.0        0.0        0.0    0.0         0.0     0.0  \n",
       "...         ...        ...        ...    ...         ...     ...  \n",
       "20047       0.0        0.0        0.0    0.0         0.0     0.0  \n",
       "20048       0.0        0.0        0.0    0.0         0.0     0.0  \n",
       "20049       0.0        0.0        0.0    0.0         0.0     1.0  \n",
       "20050       0.0        0.0        0.0    0.0         0.0     0.0  \n",
       "20051       0.0        0.0        0.0    0.0         0.0     0.0  \n",
       "\n",
       "[15864 rows x 680 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epi = epi.dropna()\n",
    "epi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating             1.285518\n",
       "calories      359848.417868\n",
       "protein         3843.462312\n",
       "fat            20459.329549\n",
       "sodium        334042.078448\n",
       "                  ...      \n",
       "cookbooks          0.011228\n",
       "leftovers          0.017751\n",
       "snack              0.036360\n",
       "snack week         0.028615\n",
       "turkey             0.144198\n",
       "Length: 679, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epi.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating           3.760952\n",
       "calories      6350.682993\n",
       "protein        100.324571\n",
       "fat            346.986826\n",
       "sodium        6252.742310\n",
       "                 ...     \n",
       "cookbooks        0.000126\n",
       "leftovers        0.000315\n",
       "snack            0.001324\n",
       "snack week       0.000819\n",
       "turkey           0.021243\n",
       "Length: 679, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epi.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.4612,  1.4620,  1.4876,  ...,  1.1964,  1.2565,  1.2898],\n",
       "          [ 1.4604,  1.4612,  1.4630,  ...,  1.2236,  1.2581,  1.2907],\n",
       "          [ 1.4466,  1.4481,  1.4550,  ...,  1.2609,  1.2956,  1.3032],\n",
       "          ...,\n",
       "          [ 1.5514,  1.3198,  1.4637,  ...,  1.7522,  1.7191,  1.7283],\n",
       "          [ 1.4293,  1.4341,  1.5262,  ...,  1.7638,  1.7646,  1.7371],\n",
       "          [ 1.3825,  1.4438,  1.5395,  ...,  1.7559,  1.7344,  1.6855]],\n",
       " \n",
       "         [[ 1.6758,  1.6766,  1.7028,  ...,  1.4082,  1.4665,  1.5006],\n",
       "          [ 1.6749,  1.6758,  1.6777,  ...,  1.4329,  1.4681,  1.5015],\n",
       "          [ 1.6609,  1.6624,  1.6695,  ...,  1.4710,  1.5065,  1.5143],\n",
       "          ...,\n",
       "          [-0.2446, -0.2617, -0.2779,  ..., -0.2630, -0.2951, -0.2858],\n",
       "          [-0.3710, -0.3652, -0.3236,  ..., -0.2629, -0.3425, -0.3705],\n",
       "          [-0.4187, -0.3553, -0.3099,  ..., -0.2710, -0.3734, -0.4234]],\n",
       " \n",
       "         [[ 1.9777,  1.9785,  2.0046,  ...,  1.7101,  1.7694,  1.8033],\n",
       "          [ 1.9769,  1.9777,  1.9796,  ...,  1.7359,  1.7710,  1.8042],\n",
       "          [ 1.9629,  1.9643,  1.9714,  ...,  1.7738,  1.8091,  1.8169],\n",
       "          ...,\n",
       "          [-1.2142, -1.5878, -1.6203,  ..., -1.7103, -1.7963, -1.8034],\n",
       "          [-1.5725, -1.5705, -1.5465,  ..., -1.7394, -1.7916, -1.8009],\n",
       "          [-1.6207, -1.5607, -1.5330,  ..., -1.7474, -1.8037, -1.8044]]]),\n",
       " tensor([-0.0170, -0.0243, -0.0160, -0.0179]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0612e-09, 1.0000e+00],\n",
       "        [5.0000e-01, 5.0000e-01]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Softmax(dim=1)(torch.tensor([[-10., 10.], [1., 1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ignite'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1598b5d1429d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ignite'"
     ]
    }
   ],
   "source": [
    "import ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, resnet50\n",
    "\n",
    "oi = resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
