{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_keys.pkl \u001b[1m\u001b[36mtrain_lmdb\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/recipe1m/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = pkl.load(open(\"../data/recipe1m/train/train_keys.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000075604a',\n",
       " '00007bfd16',\n",
       " '000095fc1d',\n",
       " '0000b1e2b5',\n",
       " '0000c79afb',\n",
       " '00010379bf',\n",
       " '00010c7867',\n",
       " '00010d44c7',\n",
       " '00013266c9',\n",
       " '00016355e6']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238459"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "det_ingrs.json             test.tar\n",
      "im2recipe_model.t7         \u001b[1m\u001b[36mtrain\u001b[m\u001b[m\n",
      "im2recipe_model.t7.gz      train.tar\n",
      "model_e220_v-4.700.pth.tar \u001b[1m\u001b[36mval\u001b[m\u001b[m\n",
      "recipe1M_images_test.tar   val.tar\n",
      "recipe1M_images_val.tar\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/recipe1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "det_ingrs = json.load(open(\"../data/recipe1m/det_ingrs.json\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'valid': [True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False,\n",
       "  False,\n",
       "  True,\n",
       "  True,\n",
       "  True,\n",
       "  False],\n",
       " 'id': '000018c8a5',\n",
       " 'ingredients': [{'text': 'penne'},\n",
       "  {'text': 'cheese sauce'},\n",
       "  {'text': 'cheddar cheese'},\n",
       "  {'text': 'gruyere cheese'},\n",
       "  {'text': 'dried chipotle powder'},\n",
       "  {'text': 'unsalted butter'},\n",
       "  {'text': 'all - purpose flour'},\n",
       "  {'text': 'milk'},\n",
       "  {'text': '14 ounces semihard cheese (page 23), grated (about 3 1/2 cups)'},\n",
       "  {'text': '2 ounces semisoft cheese (page 23), grated (1/2 cup)'},\n",
       "  {'text': 'kosher salt'},\n",
       "  {'text': 'dried chipotle powder'},\n",
       "  {'text': 'garlic powder'},\n",
       "  {'text': '(makes about 4 cups)'}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_ingrs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1029720"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(det_ingrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.load('../data/recipe1m/model_e220_v-4.700.pth.tar', map_location=\"cpu\", encoding=\"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchwordemb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1de2e738950b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchwordemb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# from args import get_parser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTableModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchwordemb'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchwordemb\n",
    "# from args import get_parser\n",
    "class TableModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TableModule, self).__init__()\n",
    "        \n",
    "    def forward(self, x, dim):\n",
    "        y = torch.cat(x, dim)\n",
    "        return y\n",
    "\n",
    "def norm(input, p=2, dim=1, eps=1e-12):\n",
    "    return input / input.norm(p,dim,keepdim=True).clamp(min=eps).expand_as(input)\n",
    "\n",
    "# Skip-thoughts LSTM\n",
    "class stRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(stRNN, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=opts.stDim, hidden_size=opts.srnnDim, bidirectional=False, batch_first=True)\n",
    "                \n",
    "    def forward(self, x, sq_lengths):\n",
    "        # here we use a previous LSTM to get the representation of each instruction \n",
    "        # sort sequence according to the length\n",
    "        sorted_len, sorted_idx = sq_lengths.sort(0, descending=True)\n",
    "        index_sorted_idx = sorted_idx\\\n",
    "                .view(-1,1,1).expand_as(x)\n",
    "        sorted_inputs = x.gather(0, index_sorted_idx.long())\n",
    "        # pack sequence\n",
    "        packed_seq = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "                sorted_inputs, sorted_len.cpu().data.numpy(), batch_first=True)\n",
    "        # pass it to the lstm\n",
    "        out, hidden = self.lstm(packed_seq)\n",
    "\n",
    "        # unsort the output\n",
    "        _, original_idx = sorted_idx.sort(0, descending=False)\n",
    "\n",
    "        unpacked, _ = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        unsorted_idx = original_idx.view(-1,1,1).expand_as(unpacked)\n",
    "        # we get the last index of each sequence in the batch\n",
    "        idx = (sq_lengths-1).view(-1,1).expand(unpacked.size(0), unpacked.size(2)).unsqueeze(1)\n",
    "        # we sort and get the last element of each sequence\n",
    "        output = unpacked.gather(0, unsorted_idx.long()).gather(1,idx.long())\n",
    "        output = output.view(output.size(0),output.size(1)*output.size(2))\n",
    "\n",
    "        return output \n",
    "\n",
    "class ingRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ingRNN, self).__init__()\n",
    "        self.irnn = nn.LSTM(input_size=opts.ingrW2VDim, hidden_size=opts.irnnDim, bidirectional=True, batch_first=True)\n",
    "        _, vec = torchwordemb.load_word2vec_bin(opts.ingrW2V)\n",
    "        self.embs = nn.Embedding(vec.size(0), opts.ingrW2VDim, padding_idx=0) # not sure about the padding idx \n",
    "        self.embs.weight.data.copy_(vec)\n",
    "\n",
    "    def forward(self, x, sq_lengths):\n",
    "\n",
    "        # we get the w2v for each element of the ingredient sequence\n",
    "        x = self.embs(x) \n",
    "\n",
    "        # sort sequence according to the length\n",
    "        sorted_len, sorted_idx = sq_lengths.sort(0, descending=True)\n",
    "        index_sorted_idx = sorted_idx\\\n",
    "                .view(-1,1,1).expand_as(x)\n",
    "        sorted_inputs = x.gather(0, index_sorted_idx.long())\n",
    "        # pack sequence\n",
    "        packed_seq = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "                sorted_inputs, sorted_len.cpu().data.numpy(), batch_first=True)\n",
    "        # pass it to the rnn\n",
    "        out, hidden = self.irnn(packed_seq)\n",
    "\n",
    "        # unsort the output\n",
    "        _, original_idx = sorted_idx.sort(0, descending=False)\n",
    "\n",
    "        # LSTM\n",
    "        # bi-directional\n",
    "        unsorted_idx = original_idx.view(1,-1,1).expand_as(hidden[0])\n",
    "        # 2 directions x batch_size x num features, we transpose 1st and 2nd dimension\n",
    "        output = hidden[0].gather(1,unsorted_idx).transpose(0,1).contiguous()\n",
    "        output = output.view(output.size(0),output.size(1)*output.size(2))\n",
    "\n",
    "        return output\n",
    "\n",
    "# Im2recipe model\n",
    "class im2recipe(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(im2recipe, self).__init__()\n",
    "        if opts.preModel=='resNet50':\n",
    "        \n",
    "            resnet = models.resnet50(pretrained=True)\n",
    "            modules = list(resnet.children())[:-1]  # we do not use the last fc layer.\n",
    "            self.visionMLP = nn.Sequential(*modules)\n",
    "\n",
    "            self.visual_embedding = nn.Sequential(\n",
    "                nn.Linear(opts.imfeatDim, opts.embDim),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "            \n",
    "            self.recipe_embedding = nn.Sequential(\n",
    "                nn.Linear(opts.irnnDim*2 + opts.srnnDim, opts.embDim, opts.embDim),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise Exception('Only resNet50 model is implemented.') \n",
    "\n",
    "        self.stRNN_     = stRNN()\n",
    "        self.ingRNN_    = ingRNN()\n",
    "        self.table      = TableModule()\n",
    " \n",
    "        if opts.semantic_reg:\n",
    "            self.semantic_branch = nn.Linear(opts.embDim, opts.numClasses)\n",
    "\n",
    "    def forward(self, x, y1, y2, z1, z2): # we need to check how the input is going to be provided to the model\n",
    "        # recipe embedding\n",
    "        recipe_emb = self.table([self.stRNN_(y1,y2), self.ingRNN_(z1,z2) ],1) # joining on the last dim \n",
    "        recipe_emb = self.recipe_embedding(recipe_emb)\n",
    "        recipe_emb = norm(recipe_emb)\n",
    "\n",
    "        # visual embedding\n",
    "        visual_emb = self.visionMLP(x)\n",
    "        visual_emb = visual_emb.view(visual_emb.size(0), -1)\n",
    "        visual_emb = self.visual_embedding(visual_emb)\n",
    "        visual_emb = norm(visual_emb)\n",
    "        \n",
    "        if opts.semantic_reg:            \n",
    "            visual_sem = self.semantic_branch(visual_emb)\n",
    "            recipe_sem = self.semantic_branch(recipe_emb)\n",
    "            # final output\n",
    "            output = [visual_emb, recipe_emb, visual_sem, recipe_sem]\n",
    "        else:\n",
    "            # final output \n",
    "            output = [visual_emb, recipe_emb] \n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install caffee\n",
    "import caffe\n",
    "import lmdb\n",
    "\n",
    "lmdb_env = lmdb.open('directory_containing_mdb')\n",
    "lmdb_txn = lmdb_env.begin()\n",
    "lmdb_cursor = lmdb_txn.cursor()\n",
    "datum = caffe.proto.caffe_pb2.Datum()\n",
    "\n",
    "for key, value in lmdb_cursor:\n",
    "    datum.ParseFromString(value)\n",
    "    label = datum.label\n",
    "    data = caffe.io.datum_to_array(datum)\n",
    "    for l, d in zip(label, data):\n",
    "            print (l, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
